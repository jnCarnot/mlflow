{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "571c92b8-847c-4f44-bc0a-cf1d67f837a5",
   "metadata": {},
   "source": [
    "# MLflow Local Run Edition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1dd3ebbc-9b15-48d6-bbbb-b13273aef006",
   "metadata": {},
   "source": [
    "*It is recommended you start a virtual environment before running the session*\n",
    "\n",
    "For MacOS:\n",
    "\n",
    "After you are in the right directory,\n",
    "\n",
    "`python3 -m venv <environment name>` <br>\n",
    "`source <environment name>/bin/activate`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c390fcf-7b95-4425-9fc2-2a285d4fd072",
   "metadata": {},
   "source": [
    "**Run `pip install mlflow` or `conda install mlflow` if you are using conda to install mlflow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "459ac9d7-e33f-4ae1-9356-73a727a0dcb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import mlflow\n",
    "from mlflow.models import infer_signature\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn import datasets\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4675c6f-a1c4-4519-85cf-a87c0dd8174b",
   "metadata": {},
   "source": [
    "**In your terminal, set up mlflow server by typing `mlflow server`, by default, http://127.0.0.1:5000 will be the tracking uri**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "051aaf67-298e-4bbb-b36b-b45af710c66f",
   "metadata": {},
   "source": [
    "**You can go to the link http://127.0.0.1:5000 to gain access to the mlflow ui**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c77f031d-4a56-4804-bfc4-034b4486b6e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri(uri=\"http://127.0.0.1:5000\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3528f701-7b86-4625-9c0e-6498e3890ec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Iris dataset\n",
    "X, y = datasets.load_iris(return_X_y=True)\n",
    "\n",
    "# Split the data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Define the model hyperparameters\n",
    "params = {\"solver\": \"lbfgs\", \"max_iter\": 1000, \"multi_class\": \"auto\", \"random_state\": 8888}\n",
    "\n",
    "# Train the model\n",
    "lr = LogisticRegression(**params)\n",
    "lr.fit(X_train, y_train)\n",
    "\n",
    "# Predict on the test set\n",
    "y_pred = lr.predict(X_test)\n",
    "\n",
    "# Calculate accuracy as a target loss metric\n",
    "accuracy = accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "87743fac-2d00-472e-b526-f53eaea9a406",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Experiment: artifact_location='mlflow-artifacts:/928213069348323692', creation_time=1704424215952, experiment_id='928213069348323692', last_update_time=1704424215952, lifecycle_stage='active', name='Example Experiment', tags={}>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlflow.set_experiment(\"Example Experiment\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b34b2f0-3451-4f9f-bacd-fca6923e3859",
   "metadata": {},
   "source": [
    "**You should see a new experiment show in the mlflow ui, on your local device, you should also see a \"mlruns\" directory**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1d600bd-a8fe-4c82-b821-c4be9aefc59a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "# Start an MLflow run\n",
    "mlflow.autolog()\n",
    "with mlflow.start_run(run_name='run1'):\n",
    "    # Log the hyperparameters\n",
    "    mlflow.log_params(params)\n",
    "\n",
    "    # Log the loss metric\n",
    "    mlflow.log_metric(\"accuracy\", accuracy)\n",
    "\n",
    "    # Set a tag that we can use to remind ourselves what this run was for\n",
    "    mlflow.set_tag(\"Training Info\", \"Basic LR model for iris data\")\n",
    "\n",
    "    # Infer the model signature\n",
    "    signature = infer_signature(X_train, lr.predict(X_train))\n",
    "    \n",
    "    # Log the model\n",
    "    model_info = mlflow.sklearn.log_model(\n",
    "        sk_model=lr,\n",
    "        artifact_path='iris_model',\n",
    "        signature=signature,\n",
    "        input_example=X_train,\n",
    "        registered_model_name=\"iris_model\", # register the model directly with log_model function\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b04a1b71-ee9c-43fd-8fd1-93ac1347a4fd",
   "metadata": {},
   "source": [
    "**Navigate to 'Model' tab in the mlflow ui (top bar), you should see a newly registered model named \"iris_model\"**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd6dc2fc-3785-44c9-9ab4-15d965b72d49",
   "metadata": {},
   "source": [
    "**Now go to the terminal and input the following command**\n",
    "\n",
    "`export MLFLOW_TRACKING_URI=\"http://127.0.0.1:5000\"` This line set up connection with mlflow\n",
    "\n",
    "`$env:MLFLOW_TRACKING_URI=\"http://127.0.0.1:5000\"` (if you are using windows)\n",
    "\n",
    "\n",
    "`mlflow models serve -m \"models:/iris_model/1\" --port 5002` This line serve the model on port 5002 (it is required to specify a port)\n",
    "\n",
    "*if you ran into an error saying pyenv is not found, follow the download instructions to download pyenv*\n",
    "\n",
    "<br>\n",
    "\n",
    "**The model is ready to be used if you see something similar to this `[2024-01-05 11:49:40 +0800] [85139] [INFO] Listening at: http://127.0.0.1:5002 (85139)`**\n",
    "\n",
    "**To use the model to make predictions, you can use the `curl` command**\n",
    "\n",
    "`curl http://127.0.0.1:5002/invocations -H 'Content-Type: application/json' -d '{\n",
    "  \"dataframe_split\": {\n",
    "      \"data\": [[6.1, 2.8, 4.7, 1.2], [5.7, 3.8, 1.7, 0.3]]\n",
    "  }\n",
    "}'`\n",
    "\n",
    "More about the curl command: https://mlflow.org/docs/latest/models.html#local-model-deployment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c38a85-31df-4bc0-87ae-b4ddcaf17e31",
   "metadata": {},
   "source": [
    "**Alternatively, once you set up the serving endpoint, instead of using curl command, you can also do a post request as follow**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "f12377c1-d879-442d-9072-106df4a85cdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'predictions': [1, 0]}\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "\n",
    "endpoint = \"http://localhost:5002/invocations\" # make sure the port number matches the one you input in terminal\n",
    "data = {\n",
    "    \"dataframe_split\": {  \n",
    "        \"data\": [[6.1, 2.8, 4.7, 1.2], [5.7, 3.8, 1.7, 0.3]]   \n",
    "    }\n",
    "}\n",
    "# do a post request\n",
    "response = requests.post(endpoint, json=data)\n",
    "print(response.json())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dc1be92-b67b-4e47-84dd-48398f20576a",
   "metadata": {},
   "source": [
    "#### Docker \n",
    "\n",
    "(noted that you will need docker installed on your computer to use this feature https://www.docker.com/products/docker-desktop/)\n",
    "\n",
    "\n",
    "**Instead of using serve to run the model, you can build a docker image instead** \n",
    "\n",
    "`mlflow models build-docker --model-uri \"models:/iris_model/1\" --name \"iris\"` This line build the docker image\n",
    "\n",
    "`docker run -p 5002:8080 iris` Run the docker container on the respective port\n",
    "\n",
    "**To use the model, you can use the exact same command as you do in model serving**\n",
    "\n",
    "`curl http://127.0.0.1:8080/invocations -H 'Content-Type: application/json' -d '{\"dataframe_split\": {\"data\": [[6.1, 2.8, 4.7, 1.2], [5.7, 3.8, 1.7, 0.3]]}}'`\n",
    "\n",
    "**!Note! Since windows does not support single quote, you have to use this command instead if you are using windows**\n",
    "\n",
    "`curl http://127.0.0.1:8080/invocations -H \"Content-Type: application/json\" -d \"{\\\"dataframe_split\\\": {\\\"data\\\": [[6.1, 2.8, 4.7, 1.2], [5.7, 3.8, 1.7, 0.3]]}}\"`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
